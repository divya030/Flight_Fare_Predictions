{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('requirements.txt') as rwq:\n",
    "    lib = rwq.readlines()\n",
    "    libb = [i.replace('\\n',\"\")   for i in lib]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m training_pipeline_config \u001b[39m=\u001b[39m config_info[TRAINING_PIPELINE_CONFIG_KEY]\n\u001b[0;32m      2\u001b[0m artifact_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(ROOT_DIR,\n\u001b[0;32m      3\u001b[0m                             training_pipeline_config[TRAINING_PIPELINE_NAME_KEY],\n\u001b[0;32m      4\u001b[0m                             training_pipeline_config[TRAINING_PIPELINE_ARTIFACT_DIR_KEY]\n\u001b[0;32m      5\u001b[0m                             )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'config_info' is not defined"
     ]
    }
   ],
   "source": [
    "training_pipeline_config = config_info[TRAINING_PIPELINE_CONFIG_KEY]\n",
    "artifact_dir = os.path.join(ROOT_DIR,\n",
    "                            training_pipeline_config[TRAINING_PIPELINE_NAME_KEY],\n",
    "                            training_pipeline_config[TRAINING_PIPELINE_ARTIFACT_DIR_KEY]\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from src.entity.config_entity import DataIngestionConfig\n",
    "\n",
    "print(DataIngestionConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from src.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from src.logger import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\python.exe' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "  \n",
    "# adding src to the system path\n",
    "sys.path.insert(0, 'f:\\\\Ineuron DS\\\\Internship\\\\Flight_Fare_Predictions/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flight_Fare.entity.config_entity import DataIngestionConfig\n",
    "from Flight_Fare.config.configuration import Configuration\n",
    "from Flight_Fare.constant import *\n",
    "from Flight_Fare.entity.config_entity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\config\\\\config.yaml'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Configuration(CONFIG_FILE_PATH,CURRENT_TIME_STAMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataIngestionConfig(dataset_download_url='https://www.kaggle.com/datasets/nikhilmittal/flight-fare-prediction-mh/download', tgz_download_dir='f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-21-00-53-09\\\\tgz_data', raw_data_dir='f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-21-00-53-09\\\\raw_data', ingested_train_dir='f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-21-00-53-09\\\\ingested_data\\\\train', ingested_test_dir='f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-21-00-53-09\\\\ingested_data\\\\test')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_data_ingestion_config()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingPipelineConfig(artifact_dir='f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.get_training_pipeline_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = x.get_data_ingestion_config().raw_data_dir\n",
    "url = x.get_data_ingestion_config().dataset_download_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-21-00-53-09\\\\raw_data'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves.urllib.request import urlretrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = urlretrieve(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\r\\n<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n\\r\\n<head>\\r\\n  <title>Kaggle: Your Home for Data Science</title>\\r\\n  <meta charset=\"utf-8\" />\\r\\n    <meta name=\"robots\" content=\"index, follow\" />\\r\\n  <meta name=\"description\" content=\"Kaggle is the world&#x2019;s largest data science community with powerful tools and resources to help you achieve your data science goals.\" />\\r\\n  <meta name=\"turbolinks-cache-control\" content=\"no-cache\" />\\r\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0\">\\r\\n  <meta name=\"theme-color\" content=\"#008ABC\" />\\r\\n  <script nonce=\"h69iKYCiiCySQQdeUXq9og==\" type=\"text/javascript\">\\r\\n    window[\"pageRequestStartTime\"] = 1689796561195;\\r\\n    window[\"pageRequestEndTime\"] = 1689796561201;\\r\\n    window[\"initialPageLoadStartTime\"] = new Date().getTime();\\r\\n  </script>\\r\\n  <link rel=\"preconnect\" href=\"https://www.google-analytics.com\" crossorigin=\"anonymous\" /><link rel=\"preconnect\" href=\"https://stats.g.doubleclick.net\" /><link rel=\"preconnect\" href=\"https://storage.googleapis.com\" /><link rel=\"preconnect\" href=\"https://apis.google.com\" />\\r\\n  <link href=\"/static/images/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\" />\\r\\n  <link rel=\"manifest\" href=\"/static/json/manifest.json\" crossorigin=\"use-credentials\">\\r\\n\\r\\n\\r\\n  <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\\r\\n  <link href=\"https://fonts.googleapis.com/icon?family=Google+Material+Icons&display=block\"\\r\\n    rel=\"preload\" as=\"style\" />\\r\\n  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\\r\\n    rel=\"preload\" as=\"style\" />\\r\\n  <link href=\"https://fonts.googleapis.com/icon?family=Google+Material+Icons&display=block\"\\r\\n    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-1\" />\\r\\n  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\\r\\n    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-2\" />\\r\\n  <script nonce=\"h69iKYCiiCySQQdeUXq9og==\" type=\"text/javascript\">\\r\\n    const styleSheetIds = [\"async-google-font-1\", \"async-google-font-2\"];\\r\\n    styleSheetIds.forEach(function (id) {\\r\\n      document.getElementById(id).addEventListener(\"load\", function() {\\r\\n        this.media = \"all\";\\r\\n      });\\r\\n    });\\r\\n  </script>\\r\\n\\r\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/vendor.css?v=347bcfc883299a7a24f3\" />\\r\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/app.css?v=81f9b0bf40d37d37cc8f\" />\\r\\n  \\r\\n    \\r\\n \\r\\n      <script nonce=\"h69iKYCiiCySQQdeUXq9og==\">\\r\\n        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement(\"style\");\\r\\n        d.appendChild(s.createTextNode(\"\"));s.head.appendChild(d);d=d.sheet;\\r\\n        y=y.map(x => d.insertRule(x + \"{ opacity: 0 !important }\"));\\r\\n        h.start=1*new Date;h.end=i=function(){y.forEach(x => x<d.cssRules.length ? d.deleteRule(x) : {})};\\r\\n        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;\\r\\n        })(window,document,[\\'.site-header-react__nav\\'],\\'dataLayer\\',2000,{\\'GTM-52LNT9S\\':true});}catch(ex){}\\r\\n    </script>\\r\\n    <script nonce=\"h69iKYCiiCySQQdeUXq9og==\">\\r\\n        window.dataLayer = window.dataLayer || [];\\r\\n        function gtag() { dataLayer.push(arguments); }\\r\\n        gtag(\\'js\\', new Date());\\r\\n        gtag(\\'config\\', \\'G-T7QHS60L4Q\\', {\\r\\n            \\'optimize_id\\': \\'GTM-52LNT9S\\',\\r\\n            \\'displayFeaturesTask\\': null,\\r\\n            \\'send_page_view\\': false,\\r\\n            \\'content_group1\\': \\'Account\\'\\r\\n        });\\r\\n    </script>\\r\\n    <script nonce=\"h69iKYCiiCySQQdeUXq9og==\" async src=\"https://www.googletagmanager.com/gtag/js?id=G-T7QHS60L4Q\"></script>\\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n  <meta name=\"twitter:site\" content=\"@Kaggle\" /> \\r\\n  \\r\\n    \\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n\\r\\n    <script nonce=\"h69iKYCiiCySQQdeUXq9og==\">window[\\'useKaggleAnalytics\\'] = true;</script>\\r\\n\\r\\n  <script id=\"gapi-target\" nonce=\"h69iKYCiiCySQQdeUXq9og==\" src=\"https://apis.google.com/js/api.js\" defer\\r\\n    async></script>\\r\\n  <script nonce=\"h69iKYCiiCySQQdeUXq9og==\" src=\"/static/assets/runtime.js?v=373aaa8ebf1383abbbcc\" data-turbolinks-track=\"reload\"></script>\\r\\n  <script nonce=\"h69iKYCiiCySQQdeUXq9og==\" src=\"/static/assets/vendor.js?v=be2408fe87edb755ed22\" data-turbolinks-track=\"reload\"></script>\\r\\n  <script nonce=\"h69iKYCiiCySQQdeUXq9og==\" src=\"/static/assets/app.js?v=7042ca81d637e89e7e0c\" data-turbolinks-track=\"reload\"></script>\\r\\n    <script nonce=\"h69iKYCiiCySQQdeUXq9og==\" type=\"text/javascript\">\\r\\n      window.kaggleStackdriverConfig = {\\r\\n        key: \\'AIzaSyA4eNqUdRRskJsCZWVz-qL655Xa5JEMreE\\',\\r\\n        projectId: \\'kaggle-161607\\',\\r\\n        service: \\'web-fe\\',\\r\\n        version: \\'ci\\',\\r\\n        userId: \\'0\\'\\r\\n      }\\r\\n    </script>\\r\\n</head>\\r\\n\\r\\n<body data-turbolinks=\"false\">\\r\\n  <main>\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n<div id=\"site-container\"></div>\\r\\n\\r\\n<div id=\"site-body\" class=\"hide\">\\r\\n    \\r\\n<div data-component-name=\"LoginRegisterPage\" style=\"display: flex; flex-direction: column; flex: 1 0 auto;\"></div><script class=\"kaggle-component\" nonce=\"h69iKYCiiCySQQdeUXq9og==\">var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark(\"LoginRegisterPage.componentCouldBootstrap\");</script>\\r\\n\\r\\n</div>\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  </main>\\r\\n</body>\\r\\n\\r\\n</html>\\r\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "url=\"https://www.kaggle.com/datasets/nikhilmittal/flight-fare-prediction-mh/download\"\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\r\\n<!DOCTYPE html>\\r\\n<html lang=\"en\">\\r\\n\\r\\n<head>\\r\\n  <title>Kaggle: Your Home for Data Science</title>\\r\\n  <meta charset=\"utf-8\" />\\r\\n    <meta name=\"robots\" content=\"index, follow\" />\\r\\n  <meta name=\"description\" content=\"Kaggle is the world&#x2019;s largest data science community with powerful tools and resources to help you achieve your data science goals.\" />\\r\\n  <meta name=\"turbolinks-cache-control\" content=\"no-cache\" />\\r\\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=5.0, minimum-scale=1.0\">\\r\\n  <meta name=\"theme-color\" content=\"#008ABC\" />\\r\\n  <script nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\" type=\"text/javascript\">\\r\\n    window[\"pageRequestStartTime\"] = 1689796588209;\\r\\n    window[\"pageRequestEndTime\"] = 1689796588215;\\r\\n    window[\"initialPageLoadStartTime\"] = new Date().getTime();\\r\\n  </script>\\r\\n  <link rel=\"preconnect\" href=\"https://www.google-analytics.com\" crossorigin=\"anonymous\" /><link rel=\"preconnect\" href=\"https://stats.g.doubleclick.net\" /><link rel=\"preconnect\" href=\"https://storage.googleapis.com\" /><link rel=\"preconnect\" href=\"https://apis.google.com\" />\\r\\n  <link href=\"/static/images/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\" />\\r\\n  <link rel=\"manifest\" href=\"/static/json/manifest.json\" crossorigin=\"use-credentials\">\\r\\n\\r\\n\\r\\n  <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin />\\r\\n  <link href=\"https://fonts.googleapis.com/icon?family=Google+Material+Icons&display=block\"\\r\\n    rel=\"preload\" as=\"style\" />\\r\\n  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\\r\\n    rel=\"preload\" as=\"style\" />\\r\\n  <link href=\"https://fonts.googleapis.com/icon?family=Google+Material+Icons&display=block\"\\r\\n    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-1\" />\\r\\n  <link href=\"https://fonts.googleapis.com/css?family=Inter:400,400i,500,500i,600,600i,700,700i&display=swap\"\\r\\n    rel=\"stylesheet\" media=\"print\" id=\"async-google-font-2\" />\\r\\n  <script nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\" type=\"text/javascript\">\\r\\n    const styleSheetIds = [\"async-google-font-1\", \"async-google-font-2\"];\\r\\n    styleSheetIds.forEach(function (id) {\\r\\n      document.getElementById(id).addEventListener(\"load\", function() {\\r\\n        this.media = \"all\";\\r\\n      });\\r\\n    });\\r\\n  </script>\\r\\n\\r\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/vendor.css?v=347bcfc883299a7a24f3\" />\\r\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/assets/app.css?v=81f9b0bf40d37d37cc8f\" />\\r\\n  \\r\\n    \\r\\n \\r\\n      <script nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\">\\r\\n        try{(function(a,s,y,n,c,h,i,d,e){d=s.createElement(\"style\");\\r\\n        d.appendChild(s.createTextNode(\"\"));s.head.appendChild(d);d=d.sheet;\\r\\n        y=y.map(x => d.insertRule(x + \"{ opacity: 0 !important }\"));\\r\\n        h.start=1*new Date;h.end=i=function(){y.forEach(x => x<d.cssRules.length ? d.deleteRule(x) : {})};\\r\\n        (a[n]=a[n]||[]).hide=h;setTimeout(function(){i();h.end=null},c);h.timeout=c;\\r\\n        })(window,document,[\\'.site-header-react__nav\\'],\\'dataLayer\\',2000,{\\'GTM-52LNT9S\\':true});}catch(ex){}\\r\\n    </script>\\r\\n    <script nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\">\\r\\n        window.dataLayer = window.dataLayer || [];\\r\\n        function gtag() { dataLayer.push(arguments); }\\r\\n        gtag(\\'js\\', new Date());\\r\\n        gtag(\\'config\\', \\'G-T7QHS60L4Q\\', {\\r\\n            \\'optimize_id\\': \\'GTM-52LNT9S\\',\\r\\n            \\'displayFeaturesTask\\': null,\\r\\n            \\'send_page_view\\': false,\\r\\n            \\'content_group1\\': \\'Account\\'\\r\\n        });\\r\\n    </script>\\r\\n    <script nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\" async src=\"https://www.googletagmanager.com/gtag/js?id=G-T7QHS60L4Q\"></script>\\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n  <meta name=\"twitter:site\" content=\"@Kaggle\" /> \\r\\n  \\r\\n    \\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n  \\r\\n    \\r\\n\\r\\n\\r\\n    <script nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\">window[\\'useKaggleAnalytics\\'] = true;</script>\\r\\n\\r\\n  <script id=\"gapi-target\" nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\" src=\"https://apis.google.com/js/api.js\" defer\\r\\n    async></script>\\r\\n  <script nonce=\"q0VbRW2n7Z4pvr+yoB31WQ==\" src=\"/static/assets/runtime.js?v=373aaa8ebf1383abbbcc\" data-turbolinks-track=\"reload\"></script>\\r\\n  <script nonce=\"q0VbRW2n7Z4pvr+yoB31WQ==\" src=\"/static/assets/vendor.js?v=be2408fe87edb755ed22\" data-turbolinks-track=\"reload\"></script>\\r\\n  <script nonce=\"q0VbRW2n7Z4pvr+yoB31WQ==\" src=\"/static/assets/app.js?v=7042ca81d637e89e7e0c\" data-turbolinks-track=\"reload\"></script>\\r\\n    <script nonce=\"q0VbRW2n7Z4pvr&#x2B;yoB31WQ==\" type=\"text/javascript\">\\r\\n      window.kaggleStackdriverConfig = {\\r\\n        key: \\'AIzaSyA4eNqUdRRskJsCZWVz-qL655Xa5JEMreE\\',\\r\\n        projectId: \\'kaggle-161607\\',\\r\\n        service: \\'web-fe\\',\\r\\n        version: \\'ci\\',\\r\\n        userId: \\'0\\'\\r\\n      }\\r\\n    </script>\\r\\n</head>\\r\\n\\r\\n<body data-turbolinks=\"false\">\\r\\n  <main>\\r\\n    \\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n<div id=\"site-container\"></div>\\r\\n\\r\\n<div id=\"site-body\" class=\"hide\">\\r\\n    \\r\\n<div data-component-name=\"LoginRegisterPage\" style=\"display: flex; flex-direction: column; flex: 1 0 auto;\"></div><script class=\"kaggle-component\" nonce=\"q0VbRW2n7Z4pvr+yoB31WQ==\">var Kaggle=window.Kaggle||{};Kaggle.State=Kaggle.State||[];Kaggle.State.push({});performance && performance.mark && performance.mark(\"LoginRegisterPage.componentCouldBootstrap\");</script>\\r\\n\\r\\n</div>\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n  </main>\\r\\n</body>\\r\\n\\r\\n</html>\\r\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"https://www.kaggle.com/louise2001/quantum-physics-articles-on-arxiv-1994-to-2009/download\"\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:Your Kaggle Key:Downloading flight-fare-prediction-mh.zip to .\\flight-fare-prediction-mh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626k/626k [00:01<00:00, 518kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import opendatasets as od\n",
    "import pandas\n",
    " \n",
    "file = od.download(\"https://www.kaggle.com/datasets/nikhilmittal/flight-fare-prediction-mh/download\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.dirname('flight-fare-prediction-mh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\flight-fare-prediction-mh\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not find kaggle.json. Make sure it's located in C:\\Users\\HP-LAPTOP\\.kaggle. Or use the environment method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkaggle\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# kaggle.api.authenticate()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[39m# kaggle.api.dataset_download_files('https://www.kaggle.com/datasets/nikhilmittal/flight-fare-prediction-mh/download', \u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m#                                  path=file, unzip=True)\u001b[39;00m\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\kaggle\\__init__.py:23\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkaggle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_client\u001b[39;00m \u001b[39mimport\u001b[39;00m ApiClient\n\u001b[0;32m     22\u001b[0m api \u001b[39m=\u001b[39m KaggleApi(ApiClient())\n\u001b[1;32m---> 23\u001b[0m api\u001b[39m.\u001b[39;49mauthenticate()\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py:403\u001b[0m, in \u001b[0;36mKaggleApi.authenticate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m         config_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread_config_file(config_data)\n\u001b[0;32m    402\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not find \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Make sure it\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms located in\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    404\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. Or use the environment method.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    405\u001b[0m                           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_file, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig_dir))\n\u001b[0;32m    407\u001b[0m \u001b[39m# Step 3: load into configuration!\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_config(config_data)\n",
      "\u001b[1;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in C:\\Users\\HP-LAPTOP\\.kaggle. Or use the environment method."
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "\n",
    "# kaggle.api.authenticate()\n",
    "\n",
    "# kaggle.api.dataset_download_files('https://www.kaggle.com/datasets/nikhilmittal/flight-fare-prediction-mh/download', \n",
    "#                                  path=file, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# your api key\n",
    "api_key = {\n",
    "'username':\"divya000\" ,\n",
    "'key':\"0fecc548237e2f24f164bbec4bb59513\"}\n",
    "\n",
    "# uses pathlib Path\n",
    "kaggle_path = Path(ROOT_DIR + '/.kaggel')\n",
    "os.makedirs(kaggle_path, exist_ok=True)\n",
    "\n",
    "# opens file and dumps python dict to json object \n",
    "with open (kaggle_path/'kaggle.json', 'w') as handl:\n",
    "    json.dump(api_key,handl)\n",
    "\n",
    "os.chmod(kaggle_path/'kaggle.json', 600)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download nikhilmittal/flight-fare-prediction-mh/download\n",
    "\n",
    "kaggle datasets download nikhilmittal/flight-fare-prediction-mh/download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "cred={\"username\":\"divya000\",\"key\":\"978f49cc6a472cdf9ded6d3a7184681e\"}\n",
    "cred_path = Path('~/.kaggle/kaggle.json').expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data must be str, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cred_path\u001b[39m.\u001b[39mparent\u001b[39m.\u001b[39mmkdir(exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m cred_path\u001b[39m.\u001b[39;49mwrite_text(cred)\n\u001b[0;32m      3\u001b[0m cred_path\u001b[39m.\u001b[39mchmod(\u001b[39m0o600\u001b[39m)\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\pathlib.py:1272\u001b[0m, in \u001b[0;36mPath.write_text\u001b[1;34m(self, data, encoding, errors)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[39mOpen the file in text mode, write to it, and close the file.\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mstr\u001b[39m):\n\u001b[1;32m-> 1272\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mdata must be str, not \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1273\u001b[0m                     data\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m   1274\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen(mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m   1275\u001b[0m     \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39mwrite(data)\n",
      "\u001b[1;31mTypeError\u001b[0m: data must be str, not dict"
     ]
    }
   ],
   "source": [
    "cred_path.parent.mkdir(exist_ok=True)\n",
    "cred_path.write_text(cred)\n",
    "cred_path.chmod(0o600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m os\u001b[39m.\u001b[39;49mcurdir()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "os.curdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('flight-fare-prediction-mh')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path('flight-fare-prediction-mh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\flight-fare-prediction-mh'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('flight-fare-prediction-mh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-01-56-20\\\\raw_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m os\u001b[39m.\u001b[39;49mchdir(file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-01-56-20\\\\raw_data'"
     ]
    }
   ],
   "source": [
    "os.chdir(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.curdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\Scripts\\kaggle.exe\\__main__.py\", line 4, in <module>\n",
      "  File \"F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\kaggle\\__init__.py\", line 23, in <module>\n",
      "    api.authenticate()\n",
      "  File \"F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\kaggle\\api\\kaggle_api_extended.py\", line 403, in authenticate\n",
      "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
      "OSError: Could not find kaggle.json. Make sure it's located in C:\\Users\\HP-LAPTOP\\.kaggle. Or use the environment method.\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets list -s filght-fare-prediction-mh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flight_Fare.exception import CustomException\n",
    "from Flight_Fare.logger import logging\n",
    "from Flight_Fare.config.configuration import Configuration\n",
    "from Flight_Fare.entity.artifact_entity import DataIngestionArtifact\n",
    "from Flight_Fare.constant import *\n",
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:Downloading flight-fare-prediction-mh.zip to .\\flight-fare-prediction-mh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 626k/626k [00:01<00:00, 560kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_ingestion_config = Configuration(CONFIG_FILE_PATH,CURRENT_TIME_STAMP)\n",
    "data_ingestion_config = data_ingestion_config.get_data_ingestion_config()\n",
    "\n",
    "download_url = data_ingestion_config.dataset_download_url\n",
    "\n",
    "#folder location to download file\n",
    "raw_data_dir = data_ingestion_config.raw_data_dir\n",
    "\n",
    "os.makedirs(raw_data_dir,exist_ok=True)\n",
    "\n",
    "os.chdir(raw_data_dir)\n",
    "od.download(download_url) \n",
    "os.chdir(ROOT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'F:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\artifact\\\\data_ingestion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m train \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mF:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mIneuron DS\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mInternship\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFFP\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFlight_Fare_Predictions\u001b[39m\u001b[39m\\a\u001b[39;00m\u001b[39mrtifact\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata_ingestion\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m'\u001b[39;49m\u001b[39mF:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mIneuron DS\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mInternship\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mFFP\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mFlight_Fare_Predictions\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39martifact\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mdata_ingestion\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'F:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\artifact\\\\data_ingestion'"
     ]
    }
   ],
   "source": [
    "train = 'F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\artifact\\data_ingestion'\n",
    "\n",
    "os.listdir('F:\\\\Ineuron DS\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\artifact\\\\data_ingestion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-21-00-53-09\\\\raw_data'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "raw_data_dir = data_ingestion_config.raw_data_dir\n",
    "\n",
    "basename = 'flight-fare-prediction-mh'\n",
    "\n",
    "raw_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file_name = os.listdir(file_path)[0]\n",
    "test_data_file_name = os.listdir(file_path)[2]\n",
    "\n",
    "train_file_path = os.path.join(file_path,train_data_file_name)\n",
    "\n",
    "test_file_path = os.path.join(file_path,test_data_file_name)\n",
    "\n",
    "train_df = pd.read_excel(train_file_path)\n",
    "test_df = pd.read_excel(test_file_path)\n",
    "\n",
    "# logging.info('Read the dataset as dataframe')\n",
    "\n",
    "os.makedirs(os.path.dirname(data_ingestion_config.ingested_train_dir),exist_ok=True)\n",
    "os.makedirs(os.path.dirname(data_ingestion_config.ingested_test_dir),exist_ok=True)\n",
    "\n",
    "train_df.to_csv(data_ingestion_config.ingested_train_dir,header=True,index = False)\n",
    "test_df.to_csv(data_ingestion_config.ingested_test_dir, header= True, index= False)\n",
    "\n",
    "# logging.info('Ingestion of the data is completed')\n",
    "\n",
    "\"\"\"return (\n",
    "                self.data_ingestion_config.ingested_train_dir,\n",
    "                self.data_ingestion_config.ingested_test_dir\n",
    "                )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-19-47-48\\\\raw_data\\\\flight-fare-prediction-mh\\\\Data_Train.xlsx'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath(train_data_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-19-47-48\\\\raw_data\\\\flight-fare-prediction-mh\\\\Data_Train.xlsx'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_dir\n",
    "file_path\n",
    "train_file_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\Flight_Fare\\artifact\\data_ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\Flight_Fare\\artifact\\data_ingestion\\2023-07-20-19-47-48\\raw_data\\flight-fare-prediction-mh\\Data_Train.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-19-47-48\\\\raw_data\\\\flight-fare-prediction-mh'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m v \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(raw_data_dir,\u001b[39m'\u001b[39m\u001b[39mflight-fare-prediction-mh\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(v,\u001b[39m'\u001b[39;49m\u001b[39mw+\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m     x \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mname\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(x)\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-19-47-48\\\\raw_data\\\\flight-fare-prediction-mh'"
     ]
    }
   ],
   "source": [
    "v = os.path.join(raw_data_dir,'flight-fare-prediction-mh')\n",
    "with open(v,'w+') as file:\n",
    "    x = file.name\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-19-47-48\\\\raw_data\\\\flight-fare-prediction-mh'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test_set.xlsx'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(v)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-20-19-47-48\\\\raw_data\\\\flight-fare-prediction-mh'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_file_path = r'F:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\Flight_Fare\\artifact\\data_ingestion\\2023-07-21-02-17-04\\raw_data'\n",
    "\n",
    "df = pd.read_csv(df_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.dtypes.values\n",
    "index = df.dtypes.index\n",
    "\n",
    "values = list(map(lambda x: str(x).replace(\"dtype('\",\"\").replace(\")'\",\"\"),values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Airline': 'object',\n",
       " 'Date_of_Journey': 'object',\n",
       " 'Source': 'object',\n",
       " 'Destination': 'object',\n",
       " 'Route': 'object',\n",
       " 'Dep_Time': 'object',\n",
       " 'Arrival_Time': 'object',\n",
       " 'Duration': 'object',\n",
       " 'Total_Stops': 'object',\n",
       " 'Additional_Info': 'object',\n",
       " 'Price': 'int64'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(index,values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flight_Fare.entity.artifact_entity import DataIngestionArtifact\n",
    "from Flight_Fare.config.configuration import Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-22-23-22-37\\\\ingested_data\\\\train'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Configuration()\n",
    "x.get_data_validation_config()\n",
    "x.get_data_ingestion_config().ingested_train_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.exists('f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-22-23-22-37\\\\ingested_data\\\\train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flight_Fare.config.configuration import Configuration\n",
    "\n",
    "x = Configuration()\n",
    "train_file_path = x.get_data_ingestion_config().ingested_train_dir\n",
    "tr = pd.read_csv(r'Flight_Fare\\artifact\\data_ingestion\\2023-07-22-23-37-59\\ingested_data\\train')\n",
    "tr.columns\n",
    "te = pd.read_csv(r'Flight_Fare\\artifact\\data_ingestion\\2023-07-22-23-37-59\\ingested_data\\test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n",
      "       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops',\n",
      "       'Additional_Info', 'Price'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n",
       "       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops',\n",
       "       'Additional_Info', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tr.columns)\n",
    "te.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m x \u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(x\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mty\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m missing_col \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m i,j \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39;49m(c,x):\n\u001b[0;32m      8\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39min\u001b[39;00m x:\n\u001b[0;32m      9\u001b[0m         \u001b[39mprint\u001b[39m(i,\u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "c = tr.columns\n",
    "x = te.columns\n",
    "x =list(x.values).append('ty')\n",
    "missing_col = []\n",
    "\n",
    "\n",
    "for i,j in zip(c,x):\n",
    "    if i in x:\n",
    "        print(i,'i')\n",
    "    if j in c:\n",
    "        print(j,'j')\n",
    "    else:\n",
    "        missing_col.append(i,j)\n",
    "\n",
    "missing_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m test_col \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(test_col\u001b[39m.\u001b[39mvalues)\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39mty\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m missing_col \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 9\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(train_col) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39;49m(test_col):\n\u001b[0;32m     10\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining_file \u001b[39m\u001b[39m{\u001b[39;00mtrain_file_path\u001b[39m}\u001b[39;00m\u001b[39m or Testing_file \u001b[39m\u001b[39m{\u001b[39;00mtest_file_path\u001b[39m}\u001b[39;00m\u001b[39m is has missing columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(message)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-22-23-37-59\\ingested_data\\train\")\n",
    "test_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-22-23-37-59\\ingested_data\\test\")\n",
    "\n",
    "train_col = train_df.columns\n",
    "test_col = test_df.columns\n",
    "test_col = list(test_col.values).append('ty')\n",
    "missing_col = []\n",
    "\n",
    "if len(train_col) != len(test_col):\n",
    "    message = f\"Training_file {train_file_path} or Testing_file {test_file_path} is has missing columns\"\n",
    "    raise Exception(message)\n",
    "else:\n",
    "    # Column names \n",
    "    missing_col = []\n",
    "\n",
    "    for i,j in zip(train_col,test_col):\n",
    "        if i in test_col:\n",
    "            continue\n",
    "        if j in train_col:\n",
    "            continue\n",
    "        \n",
    "        else:\n",
    "            missing_col.append(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Airline', 'Date_of_Journey', 'Source', 'Destination', 'Route',\n",
       "       'Dep_Time', 'Arrival_Time', 'Duration', 'Total_Stops',\n",
       "       'Additional_Info', 'Price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train_col) != len(test_col):\n",
    "                message = f\"Training_file {train_file_path} or Testing_file {test_file_path} is has missing columns\"\n",
    "                raise Exception(message)\n",
    "            else:\n",
    "                # Column names \n",
    "                missing_col = []\n",
    "\n",
    "                for i,j in zip(train_col,test_col):\n",
    "                    if i in test_col:\n",
    "                        continue\n",
    "                    if j in train_col:\n",
    "                        continue\n",
    "                    \n",
    "                    else:\n",
    "                        missing_col.append(i,j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing C:\\Users\\HP-LAPTOP\\AppData\\Roaming\\Python\\Python39\\site-packages\\evidently\\nbextension/static -> evidently\n",
      "Symlinking: C:\\Users\\HP-LAPTOP\\anaconda3\\share\\jupyter\\nbextensions\\evidently -> C:\\Users\\HP-LAPTOP\\AppData\\Roaming\\Python\\Python39\\site-packages\\evidently\\nbextension\\static\n",
      "- Validating: ok\n",
      "\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
      "    \n",
      "          jupyter nbextension enable evidently --py --sys-prefix\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension install --sys-prefix --symlink --overwrite --py evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'evidently.dashboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mevidently\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdashboard\u001b[39;00m \u001b[39mimport\u001b[39;00m Dashboard\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mevidently\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdashboard\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtabs\u001b[39;00m \u001b[39mimport\u001b[39;00m DataDriftTab\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'evidently.dashboard'"
     ]
    }
   ],
   "source": [
    "from evidently.dashboard import Dashboard\n",
    "from evidently.dashboard.tabs import DataDriftTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evidently in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (0.4.0)\n",
      "Requirement already satisfied: plotly>=5.5.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (5.15.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (0.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (1.2.2)\n",
      "Requirement already satisfied: pandas>=1.3.5 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (1.24.4)\n",
      "Requirement already satisfied: nltk>=3.6.7 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (3.8.1)\n",
      "Requirement already satisfied: umap-learn>=0.5.3 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (0.5.3)\n",
      "Requirement already satisfied: scipy>=1.5.4 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (1.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (2.31.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (6.0.1)\n",
      "Requirement already satisfied: pydantic<2,>=1.10 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (1.10.11)\n",
      "Requirement already satisfied: fastapi>=0.98.0 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (0.100.0)\n",
      "Requirement already satisfied: uvicorn>=0.22.0 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (0.23.1)\n",
      "Requirement already satisfied: typer>=0.9 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (0.9.0)\n",
      "Requirement already satisfied: rich>=13 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (13.4.2)\n",
      "Requirement already satisfied: iterative-telemetry==0.0.5 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (0.0.5)\n",
      "Requirement already satisfied: appdirs in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from iterative-telemetry==0.0.5->evidently) (1.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from iterative-telemetry==0.0.5->evidently) (3.12.2)\n",
      "Requirement already satisfied: distro in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from iterative-telemetry==0.0.5->evidently) (1.8.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from fastapi>=0.98.0->evidently) (0.27.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from fastapi>=0.98.0->evidently) (4.7.1)\n",
      "Requirement already satisfied: click in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from nltk>=3.6.7->evidently) (8.1.6)\n",
      "Requirement already satisfied: joblib in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from nltk>=3.6.7->evidently) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from nltk>=3.6.7->evidently) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from nltk>=3.6.7->evidently) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.3.5->evidently) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.3.5->evidently) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.3.5->evidently) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from plotly>=5.5.0->evidently) (8.2.2)\n",
      "Requirement already satisfied: packaging in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from plotly>=5.5.0->evidently) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (2023.5.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from rich>=13->evidently) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from rich>=13->evidently) (2.15.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from scikit-learn>=0.24.0->evidently) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels>=0.12.2->evidently) (0.5.3)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from umap-learn>=0.5.3->evidently) (0.57.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from umap-learn>=0.5.3->evidently) (0.5.10)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from uvicorn>=0.22.0->evidently) (0.14.0)\n",
      "Requirement already satisfied: colorama in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from click->nltk>=3.6.7->evidently) (0.4.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich>=13->evidently) (0.1.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from numba>=0.49->umap-learn>=0.5.3->evidently) (0.40.1)\n",
      "Requirement already satisfied: six in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.12.2->evidently) (1.16.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.98.0->evidently) (3.7.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.98.0->evidently) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.98.0->evidently) (1.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m evidently\u001b[39m.\u001b[39;49mversion_info()\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "evidently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evidently==0.1.51.dev0\n",
      "  Downloading evidently-0.1.51.dev0-py3-none-any.whl (11.9 MB)\n",
      "     ---------------------------------------- 0.0/11.9 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/11.9 MB 3.5 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.5/11.9 MB 5.0 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.8/11.9 MB 6.4 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.9 MB 6.6 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.9 MB 6.6 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.9 MB 6.6 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.9 MB 6.6 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/11.9 MB 6.6 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 1.6/11.9 MB 3.3 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 2.1/11.9 MB 3.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.4/11.9 MB 1.7 MB/s eta 0:00:06\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ----------------------------- 3.1/11.9 MB 2.2 MB/s eta 0:00:05\n",
      "     ---------- ---------------------------- 3.2/11.9 MB 621.7 kB/s eta 0:00:14\n",
      "     ------------ -------------------------- 3.8/11.9 MB 722.0 kB/s eta 0:00:12\n",
      "     ------------- ------------------------- 4.2/11.9 MB 793.4 kB/s eta 0:00:10\n",
      "     ------------- ------------------------- 4.2/11.9 MB 793.4 kB/s eta 0:00:10\n",
      "     ------------- ------------------------- 4.2/11.9 MB 793.4 kB/s eta 0:00:10\n",
      "     ------------- ------------------------- 4.2/11.9 MB 793.4 kB/s eta 0:00:10\n",
      "     -------------- ------------------------ 4.3/11.9 MB 784.5 kB/s eta 0:00:10\n",
      "     ---------------- ---------------------- 5.0/11.9 MB 909.0 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ----------------- --------------------- 5.2/11.9 MB 943.3 kB/s eta 0:00:08\n",
      "     ------------------ -------------------- 5.8/11.9 MB 954.2 kB/s eta 0:00:07\n",
      "     -------------------- ------------------- 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 6.2/11.9 MB 1.0 MB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.2/11.9 MB 968.6 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 958.6 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 958.6 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 948.1 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     -------------------- ------------------ 6.3/11.9 MB 945.2 kB/s eta 0:00:06\n",
      "     ---------------------- ---------------- 6.9/11.9 MB 460.5 kB/s eta 0:00:11\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.3/11.9 MB 491.2 kB/s eta 0:00:10\n",
      "     ------------------------ -------------- 7.5/11.9 MB 485.9 kB/s eta 0:00:09\n",
      "     ------------------------- ------------- 7.9/11.9 MB 507.6 kB/s eta 0:00:08\n",
      "     --------------------------- ----------- 8.4/11.9 MB 539.2 kB/s eta 0:00:07\n",
      "     --------------------------- ----------- 8.4/11.9 MB 539.9 kB/s eta 0:00:07\n",
      "     --------------------------- ----------- 8.4/11.9 MB 539.9 kB/s eta 0:00:07\n",
      "     --------------------------- ----------- 8.4/11.9 MB 539.9 kB/s eta 0:00:07\n",
      "     --------------------------- ----------- 8.4/11.9 MB 539.9 kB/s eta 0:00:07\n",
      "     --------------------------- ----------- 8.4/11.9 MB 539.9 kB/s eta 0:00:07\n",
      "     ---------------------------- ---------- 8.8/11.9 MB 554.9 kB/s eta 0:00:06\n",
      "     ------------------------------ -------- 9.4/11.9 MB 592.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     ------------------------------- ------- 9.4/11.9 MB 594.6 kB/s eta 0:00:05\n",
      "     -------------------------------- ------ 9.8/11.9 MB 601.2 kB/s eta 0:00:04\n",
      "     --------------------------------- ---- 10.3/11.9 MB 627.7 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 10.5/11.9 MB 628.9 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 10.5/11.9 MB 628.9 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 10.5/11.9 MB 628.9 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 10.5/11.9 MB 628.9 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 10.5/11.9 MB 628.9 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 10.5/11.9 MB 628.9 kB/s eta 0:00:03\n",
      "     --------------------------------- ---- 10.5/11.9 MB 628.9 kB/s eta 0:00:03\n",
      "     ---------------------------------- --- 10.7/11.9 MB 616.5 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 11.2/11.9 MB 616.5 kB/s eta 0:00:02\n",
      "     ------------------------------------ - 11.5/11.9 MB 627.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.5/11.9 MB 627.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.5/11.9 MB 627.1 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 11.5/11.9 MB 627.1 kB/s eta 0:00:01\n",
      "     -------------------------------------  11.8/11.9 MB 619.4 kB/s eta 0:00:01\n",
      "     -------------------------------------  11.8/11.9 MB 619.4 kB/s eta 0:00:01\n",
      "     -------------------------------------- 11.9/11.9 MB 615.1 kB/s eta 0:00:00\n",
      "Collecting dataclasses>=0.6 (from evidently==0.1.51.dev0)\n",
      "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: plotly>=5.5.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently==0.1.51.dev0) (5.15.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently==0.1.51.dev0) (0.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently==0.1.51.dev0) (1.2.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently==0.1.51.dev0) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently==0.1.51.dev0) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.4 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently==0.1.51.dev0) (1.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently==0.1.51.dev0) (2.31.0)\n",
      "Collecting PyYAML~=5.1 (from evidently==0.1.51.dev0)\n",
      "  Downloading PyYAML-5.4.1-cp39-cp39-win_amd64.whl (213 kB)\n",
      "     ---------------------------------------- 0.0/213.4 kB ? eta -:--:--\n",
      "     ------------------------------------- 213.4/213.4 kB 12.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.1.5->evidently==0.1.51.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.1.5->evidently==0.1.51.dev0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.1.5->evidently==0.1.51.dev0) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from plotly>=5.5.0->evidently==0.1.51.dev0) (8.2.2)\n",
      "Requirement already satisfied: packaging in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from plotly>=5.5.0->evidently==0.1.51.dev0) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently==0.1.51.dev0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently==0.1.51.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently==0.1.51.dev0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently==0.1.51.dev0) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from scikit-learn>=0.23.2->evidently==0.1.51.dev0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from scikit-learn>=0.23.2->evidently==0.1.51.dev0) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels>=0.12.2->evidently==0.1.51.dev0) (0.5.3)\n",
      "Requirement already satisfied: six in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.12.2->evidently==0.1.51.dev0) (1.16.0)\n",
      "Installing collected packages: dataclasses, PyYAML, evidently\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: evidently\n",
      "    Found existing installation: evidently 0.4.0\n",
      "    Uninstalling evidently-0.4.0:\n",
      "      Successfully uninstalled evidently-0.4.0\n",
      "Successfully installed PyYAML-5.4.1 dataclasses-0.6 evidently-0.1.51.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install evidently==0.1.51.dev0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy.version' from 'C:\\\\Users\\\\HP-LAPTOP\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\numpy\\\\version.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flight_Fare.constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\config\\\\config.yaml'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'columns': {'Airline': 'object,', 'Date_of_Journey': 'object,', 'Source': 'object,', 'Destination': 'object,', 'Route': 'object,', 'Dep_Time': 'object,', 'Arrival_Time': 'object,', 'Duration': 'object,', 'Total_Stops': 'object,', 'Additional_Info': 'object,', 'Price': 'int64'}, 'target_column': 'Price'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(SCHEMA_FILE_PATH,'rb') as yaml_file:\n",
    "             print(yaml.safe_load(yaml_file))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': {'Airline': 'object,',\n",
       "  'Date_of_Journey': 'object,',\n",
       "  'Source': 'object,',\n",
       "  'Destination': 'object,',\n",
       "  'Route': 'object,',\n",
       "  'Dep_Time': 'object,',\n",
       "  'Arrival_Time': 'object,',\n",
       "  'Duration': 'object,',\n",
       "  'Total_Stops': 'object,',\n",
       "  'Additional_Info': 'object,',\n",
       "  'Price': 'int64'},\n",
       " 'target_column': 'Price'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Flight_Fare.util.util import read_yaml_file\n",
    "\n",
    "x = read_yaml_file(file_path=SCHEMA_FILE_PATH)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from evidently.model_profile import Profile\n",
    "from evidently.model_profile.sections import DataDriftProfileSection\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.dashboard.tabs import DataDriftTab\n",
    "from Flight_Fare.component.data_validation import Datavalidation\n",
    "from Flight_Fare.entity.artifact_entity import DataValidationArtifact\n",
    "from Flight_Fare.config.configuration import Configuration\n",
    "from Flight_Fare.constant import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from evidently.dashboard import Dashboard\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.dashboard.tabs import DataDriftTab\n",
    "\n",
    "from evidently.model_profile import Profile\n",
    "from evidently.model_profile.sections import DataDriftProfileSection,CatTargetDriftProfileSection\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evidently in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (0.1.51.dev0)\n",
      "Requirement already satisfied: dataclasses>=0.6 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (0.6)\n",
      "Requirement already satisfied: plotly>=5.5.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (5.15.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from evidently) (0.14.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (1.2.2)\n",
      "Requirement already satisfied: pandas>=1.1.5 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.19.5 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (1.23.0)\n",
      "Requirement already satisfied: scipy>=1.5.4 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (1.9.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (2.31.0)\n",
      "Requirement already satisfied: PyYAML~=5.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from evidently) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.1.5->evidently) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.1.5->evidently) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from pandas>=1.1.5->evidently) (2023.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from plotly>=5.5.0->evidently) (8.2.2)\n",
      "Requirement already satisfied: packaging in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from plotly>=5.5.0->evidently) (23.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from requests>=2.19.0->evidently) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from scikit-learn>=0.23.2->evidently) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from scikit-learn>=0.23.2->evidently) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\hp-laptop\\appdata\\roaming\\python\\python39\\site-packages (from statsmodels>=0.12.2->evidently) (0.5.3)\n",
      "Requirement already satisfied: six in f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.12.2->evidently) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -umpy (f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (f:\\ineuron ds\\internship\\ffp\\flight_fare_predictions\\venv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\train\\Flight_Fare_Prediction.csv\")\n",
    "test_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\test\\Flight_Fare_Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17568\\236128578.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata_drift_dashboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDashboard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtabs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mDataDriftTab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata_drift_dashboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\evidently\\dashboard\\dashboard.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, reference_data, current_data, column_mapping)\u001b[0m\n\u001b[0;32m    148\u001b[0m                   \u001b[0mreference_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                   \u001b[0mcurrent_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                   column_mapping: Optional[ColumnMapping] = None):\n\u001b[0;32m    151\u001b[0m         \u001b[0mcolumn_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_mapping\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mColumnMapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\evidently\\pipeline\\pipeline.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, reference_data, current_data, column_mapping)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mcdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcurrent_data\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcurrent_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_analyzers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions_provider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions_provider\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyzers_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions_provider\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions_provider\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             stage.calculate(\n",
      "\u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\evidently\\analyzers\\data_drift_analyzer.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, reference_data, current_data, column_mapping)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnum_feature_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_drift_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mfeature_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"num\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             test = get_stattest(reference_data[feature_name],\n\u001b[0m\u001b[0;32m    104\u001b[0m                                 \u001b[0mcurrent_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                                 \u001b[0mfeature_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                                 data_drift_options.get_feature_stattest_func(feature_name, feature_type))\n",
      "\u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\evidently\\analyzers\\stattests\\registry.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(reference_data, current_data, feature_type, stattest_func)\u001b[0m\n\u001b[0;32m     65\u001b[0m                  \u001b[0mcurrent_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                  \u001b[0mfeature_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                  stattest_func: Optional[PossibleStatTestType]) -> StatTest:\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstattest_func\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_get_default_stattest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstattest_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStatTest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstattest_func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstattest_func\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstattest_func\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_registered_stat_test_funcs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\evidently\\analyzers\\stattests\\registry.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(reference_data, current_data, feature_type)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_default_stattest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_data\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mStatTest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[0mn_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreference_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreference_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"num\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_values\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "data_drift_dashboard = Dashboard(tabs=[DataDriftTab()])\n",
    "data_drift_dashboard.calculate(train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 51, 'dev0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evidently\n",
    "\n",
    "evidently.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip uninstall evidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flight_Fare.entity.artifact_entity import *\n",
    "from Flight_Fare.entity.config_entity import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_ingestion\\\\2023-07-25-01-28-46\\\\ingested_data\\\\train'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Flight_Fare.config.configuration import Configuration\n",
    "\n",
    "x = Configuration()\n",
    "x.get_data_ingestion_config().ingested_train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_tuplegetter(1, 'Alias for field number 1')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataIngestionArtifact.test_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_collections._tuplegetter' object has no attribute '_asdict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DataValidationConfig\u001b[39m.\u001b[39;49mschema_file_path\u001b[39m.\u001b[39;49m_asdict()\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_collections._tuplegetter' object has no attribute '_asdict'"
     ]
    }
   ],
   "source": [
    "DataValidationConfig.schema_file_path._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_collections._tuplegetter' object has no attribute '_fields'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m DataValidationConfig\u001b[39m.\u001b[39;49m_asdict(DataValidationConfig\u001b[39m.\u001b[39;49mschema_file_path)\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\collections\\__init__.py:462\u001b[0m, in \u001b[0;36mnamedtuple.<locals>._asdict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_asdict\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    461\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mReturn a new dict which maps field names to their values.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 462\u001b[0m     \u001b[39mreturn\u001b[39;00m _dict(_zip(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fields, \u001b[39mself\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: '_collections._tuplegetter' object has no attribute '_fields'"
     ]
    }
   ],
   "source": [
    "DataValidationConfig._asdict(DataValidationConfig.schema_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\train\\Flight_Fare_Prediction.csv\")\n",
    "test_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\test\\Flight_Fare_Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "f:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_of_Journey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7473</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7474</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7475</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7476</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7477</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7478 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_of_Journey\n",
       "0                  27\n",
       "1                   3\n",
       "2                  27\n",
       "3                   9\n",
       "4                   9\n",
       "...               ...\n",
       "7473               27\n",
       "7474                9\n",
       "7475               15\n",
       "7476                3\n",
       "7477                1\n",
       "\n",
       "[7478 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = train_df['Date_of_Journey'].str.split('/').str[0].astype(int)\n",
    "pd.DataFrame(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\Ineuron DS\\\\Internship\\\\FFP\\\\Flight_Fare_Predictions\\\\Flight_Fare\\\\artifact\\\\data_transformation\\\\2023-07-25-13-32-53\\\\preprocessed\\\\preprocessed.pkl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Flight_Fare.config.configuration import Configuration\n",
    "from Flight_Fare.constant import *\n",
    "\n",
    "config = Configuration(CONFIG_FILE_PATH,CURRENT_TIME_STAMP)\n",
    "transformation_config = config.get_data_transformation_config()\n",
    "\n",
    "transformation_config.preprocessed_object_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator():\n",
    "\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self):\n",
    "        return self\n",
    "    \n",
    "    def transform(self):\n",
    "        \n",
    "        # Date_of_Journey\n",
    "\n",
    "        journey_day = self.columns.str.split('/').str[0].astype(int)\n",
    "\n",
    "        journey_month = self.columns.str.split('/').str[1].str[1].astype(int)\n",
    "\n",
    "        # self.x.drop('Date_of_Journey',inplace = True,axis = 1)\n",
    "\n",
    "        # Dep_Time\n",
    "\n",
    "        Dep_hr = self.columns.str.split(':').str[0].astype(int)\n",
    "\n",
    "        Dep_min = self.columns.str.split(':').str[1].astype(int)\n",
    "\n",
    "        # self.x.drop('Dep_Time',inplace = True,axis = 1)\n",
    "        \n",
    "        # Arrival_Time\n",
    "\n",
    "        Arrival_hr = self.columns.str.split(\" \").str[0].str.split(':').str[0].astype(int)\n",
    "\n",
    "        Arrival_min = self.columns.str.split(\" \").str[0].str.split(':').str[1].astype(int)\n",
    "\n",
    "        # self.x.drop('Arrival_Time',inplace = True,axis = 1)\n",
    "\n",
    "        c = np.c[journey_day,journey_month,Dep_hr,Dep_min,Arrival_hr,Arrival_min]\n",
    "\n",
    "\n",
    "        return  c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator,TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Flight_Fare.config.configuration import Configuration\n",
    "from Flight_Fare.entity.artifact_entity import *\n",
    "from Flight_Fare.entity.config_entity import *\n",
    "from Flight_Fare.constant import *\n",
    "from Flight_Fare.util.util import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from Flight_Fare.exception import CustomException\n",
    "from Flight_Fare.logger import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\train\\Flight_Fare_Prediction.csv\")\n",
    "test_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\test\\Flight_Fare_Prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureGenerator(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    def __init__(self,columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return df\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "\n",
    "        if self.columns == 'Date_of_Journey':\n",
    "            try:\n",
    "                journey_day = X['Date_of_Journey'].str.split('/').str[0].astype(int)\n",
    "                journey_month = X['Date_of_Journey'].str.split('/').str[1].str[1].astype(int)\n",
    "\n",
    "                # Since we have converted Date_of_Journey column into integers, Now we can drop as it is of no use.\n",
    "                # df.drop('Date_of_Journey',inplace = True,axis = 1)\n",
    "            except Exception as e:\n",
    "                raise CustomException(sys,e)\n",
    "            \n",
    "        elif self.columns == 'Dep_Time':\n",
    "            try:\n",
    "                Dep_hr = X['Dep_Time'].str.split(':').str[0].astype(int)\n",
    "                Dep_min = X['Dep_Time'].str.split(':').str[1].astype(int)\n",
    "\n",
    "                # Since we have converted Dep_Time column into integers, Now we can drop as it is of no use.\n",
    "                # df.drop('Dep_Time',inplace = True,axis = 1)\n",
    "\n",
    "            except Exception as e:\n",
    "                raise CustomException(sys,e)\n",
    "            \n",
    "\n",
    "        elif self.columns == 'Arrival_Time':\n",
    "            try:\n",
    "                Arrival_hr = X['Arrival_Time'].str.split(\" \").str[0].str.split(':').str[0].astype(int)\n",
    "                Arrival_min = X['Arrival_Time'].str.split(\" \").str[0].str.split(':').str[1].astype(int)\n",
    "\n",
    "\n",
    "                # Since we have converted Dep_Time column into integers, Now we can drop as it is of no use.\n",
    "                # df.drop('Arrival_Time',inplace = True,axis = 1)\n",
    "\n",
    "            except Exception as e:\n",
    "                raise CustomException(sys,e)\n",
    "            \n",
    "\n",
    "        elif self.columns == 'Duration':\n",
    "            X['Duration_hr'] = 0\n",
    "            X['Duration_min'] = 0\n",
    "        \n",
    "            try:\n",
    "\n",
    "                duration = list(X['Duration'])\n",
    "\n",
    "                for i in range(len(duration)):\n",
    "                    if 'h' not in duration[i]:\n",
    "                        duration[i] = '0h ' + duration[i]\n",
    "                        \n",
    "                    if 'm' not in duration[i]:\n",
    "                        duration[i] = duration[i] + ' 0m'\n",
    "                        \n",
    "                for i in range(len(duration)):\n",
    "                    hr = int(duration[i].split(\"h\")[0])\n",
    "                    min_ = int(duration[i].split(\" \")[1].split(\"m\")[0])\n",
    "                    X['Duration_hr'][i] = hr\n",
    "                    X['Duration_min'][i] = min_\n",
    "                    \n",
    "                    \n",
    "                # Since we have converted Duration column into integers, Now we can drop as it is of no use.\n",
    "\n",
    "                # df.drop('Duration',inplace = True,axis = 1)\n",
    "\n",
    "\n",
    "                # Since there are some nan values represting 0 mins , we are replacing those values with 0 \n",
    "\n",
    "                X['Duration_min'].fillna(0,inplace = True)\n",
    "\n",
    "            except Exception as e:\n",
    "                raise CustomException(sys,e)\n",
    "            \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransformation:\n",
    "    def __init__(self,data_transformation_config: DataTransformationConfig,\n",
    "                 data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_artifact: DataValidationArtifact):\n",
    "        \n",
    "        try:\n",
    "            logging.info(f\"{'>>' * 30}Data Transformation log started.{'<<' * 30} \")\n",
    "            self.data_transformation_config= data_transformation_config\n",
    "            self.data_ingestion_artifact = data_ingestion_artifact\n",
    "            self.data_validation_artifact = data_validation_artifact\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys) from e\n",
    "        \n",
    "\n",
    "    def get_data_transformer_object(self) -> ColumnTransformer:\n",
    "        try:\n",
    "            schema_file_path = SCHEMA_FILE_PATH\n",
    "\n",
    "            dataset_schema = read_yaml_file(file_path=schema_file_path)\n",
    "\n",
    "            num_cols = dataset_schema[NUMERICAL_COLUMN_KEY]\n",
    "            cat_one = dataset_schema[CATEGORICAL_COLUMN_KEY]\n",
    "            cat_label_coding = dataset_schema[CATEGORICAL_COLUMN_KEY_LABEL]\n",
    "\n",
    "            num_pipeline = Pipeline(steps=[\n",
    "                # ('feature_generator', FeatureGenerator(columns=num_cols)),\n",
    "                ('scaler', StandardScaler())\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline = Pipeline(steps=[\n",
    "                 ('one_hot_encoder', OneHotEncoder()),\n",
    "                 ('scaler', StandardScaler(with_mean=False))\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            cat_label = Pipeline(steps=[\n",
    "            ('Labe_encoding',LabelEncoder()),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "            ]\n",
    "            )\n",
    "\n",
    "\n",
    "            logging.info(f\"Categorical columns performing One Hot Encoding: {cat_one}\")\n",
    "            logging.info(f\"Numerical columns: {num_cols}\")\n",
    "            logging.info(f\"Categorical column performing Label encoding:{cat_label_coding}\")\n",
    "\n",
    "\n",
    "            preprocessing = ColumnTransformer(transformers = [\n",
    "                ('num_pipeline', num_pipeline, num_cols),\n",
    "                ('cat_pipeline', cat_pipeline, cat_one),\n",
    "                ('cat_label',cat_label,cat_label_coding)\n",
    "            ])\n",
    "            return preprocessing\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(sys,e) from e\n",
    "        \n",
    "\n",
    "    def initiate_data_transformation(self)->DataTransformationArtifact:\n",
    "        try:\n",
    "            logging.info(f\"Obtaining preprocessing object.\")\n",
    "\n",
    "            preprocessing_obj = self.get_data_transformer_object()\n",
    "\n",
    "            config = Configuration(CONFIG_FILE_PATH,CURRENT_TIME_STAMP)\n",
    "            ingestion = config.get_data_ingestion_config()\n",
    "            basename = 'Flight_Fare_Prediction.csv'\n",
    "\n",
    "            train_file_path = os.path.join(ingestion.ingested_train_dir,basename)\n",
    "            test_file_path = os.path.join(ingestion.ingested_test_dir,basename)\n",
    "\n",
    "            logging.info(f\"Loading training and test data as pandas dataframe.\")\n",
    "\n",
    "            train_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\train\\Flight_Fare_Prediction.csv\")\n",
    "            test_df = pd.read_csv(r\"Flight_Fare\\artifact\\data_ingestion\\2023-07-25-01-27-30\\ingested_data\\test\\Flight_Fare_Prediction.csv\")\n",
    "\n",
    "            schema = read_yaml_file(file_path=SCHEMA_FILE_PATH)\n",
    "\n",
    "            target_column_name = schema[TARGET_COLUMN_KEY]\n",
    "\n",
    "            # Drop missing values \n",
    "            train_df.dropna(inplace = True)\n",
    "            test_df.dropna(inplace = True)\n",
    "\n",
    "            # Drop Trujet airline since it has one entry\n",
    "            indexx = train_df[train_df['Airline'] == 'Trujet'].index[0]\n",
    "            train_df.drop(index = indexx,inplace = True)\n",
    "\n",
    "            logging.info(f\"Splitting input and target feature from training and testing dataframe.\")\n",
    "\n",
    "            input_feature_train_df = train_df.drop(columns=[target_column_name],axis = 1)\n",
    "            input_feature_test_df = test_df.drop(columns=[target_column_name],axis = 1)\n",
    "\n",
    "            target_feature_train_df = train_df[target_column_name]\n",
    "            target_feature_test_df = test_df[target_column_name]\n",
    "\n",
    "            logging.info(f\"Applying preprocessing object on training dataframe and testing dataframe\")\n",
    "\n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr = preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "            train_arr = np.c_[ input_feature_train_arr, np.array(target_feature_train_df)]\n",
    "\n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "\n",
    "            transformed_train_dir = self.data_transformation_config.transformed_train_dir\n",
    "            transformed_test_dir = self.data_transformation_config.transformed_test_dir\n",
    "\n",
    "            train_file_name = os.path.basename(train_file_path).replace(\".csv\",\".npz\")\n",
    "            test_file_name = os.path.basename(test_file_path).replace(\".csv\",\".npz\")\n",
    "\n",
    "            transformed_train_file_path = os.path.join(transformed_train_dir, train_file_name)\n",
    "            transformed_test_file_path = os.path.join(transformed_test_dir, test_file_name)\n",
    "\n",
    "            logging.info(f\"Saving transformed training and testing array.\")\n",
    "\n",
    "            save_numpy_array_data(file_path=transformed_train_file_path,array=train_arr)\n",
    "            save_numpy_array_data(file_path=transformed_test_file_path,array=test_arr)\n",
    "\n",
    "            preprocessing_obj_file_path = self.data_transformation_config.preprocessed_object_file_path\n",
    "\n",
    "            logging.info(f\"Saving preprocessing object.\")\n",
    "            save_object(file_path=preprocessing_obj_file_path,obj=preprocessing_obj)\n",
    "\n",
    "            data_transformation_artifact = DataTransformationArtifact(is_transformed=True,\n",
    "            message=\"Data transformation successfull.\",\n",
    "            transformed_train_file_path=transformed_train_file_path,\n",
    "            transformed_test_file_path=transformed_test_file_path,\n",
    "            preprocessed_object_file_path=preprocessing_obj_file_path\n",
    "\n",
    "            )\n",
    "            logging.info(f\"Data transformationa artifact: {data_transformation_artifact}\")\n",
    "            return data_transformation_artifact\n",
    "\n",
    "            return input_feature_train_arr\n",
    "        except Exception as e:\n",
    "            raise CustomException(e,sys) from e\n",
    "\n",
    "    def __del__(self):\n",
    "        logging.info(f\"{'>>'*30}Data Transformation log completed.{'<<'*30} \\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey,'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:448\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns:\n\u001b[1;32m--> 448\u001b[0m     col_idx \u001b[39m=\u001b[39m all_columns\u001b[39m.\u001b[39;49mget_loc(col)\n\u001b[0;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col_idx, numbers\u001b[39m.\u001b[39mIntegral):\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey,'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m trans \u001b[39m=\u001b[39m DataTransformation(data_transformation_config \u001b[39m=\u001b[39m  DataTransformationConfig,\n\u001b[0;32m      2\u001b[0m                              data_ingestion_artifact \u001b[39m=\u001b[39m  DataIngestionArtifact,\n\u001b[0;32m      3\u001b[0m                              data_validation_artifact \u001b[39m=\u001b[39m DataValidationArtifact)\n\u001b[0;32m      4\u001b[0m preprocessing_obj \u001b[39m=\u001b[39m trans\u001b[39m.\u001b[39mget_data_transformer_object()\n\u001b[1;32m----> 5\u001b[0m preprocessing_obj\u001b[39m.\u001b[39;49mfit_transform(X)\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:724\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    723\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 724\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_column_callables(X)\n\u001b[0;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    727\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:426\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    424\u001b[0m         columns \u001b[39m=\u001b[39m columns(X)\n\u001b[0;32m    425\u001b[0m     all_columns\u001b[39m.\u001b[39mappend(columns)\n\u001b[1;32m--> 426\u001b[0m     transformer_to_input_indices[name] \u001b[39m=\u001b[39m _get_column_indices(X, columns)\n\u001b[0;32m    428\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_columns \u001b[39m=\u001b[39m all_columns\n\u001b[0;32m    429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer_to_input_indices \u001b[39m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:456\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    453\u001b[0m             column_indices\u001b[39m.\u001b[39mappend(col_idx)\n\u001b[0;32m    455\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 456\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mA given column is not a column of the dataframe\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[39mreturn\u001b[39;00m column_indices\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "trans = DataTransformation(data_transformation_config =  DataTransformationConfig,\n",
    "                             data_ingestion_artifact =  DataIngestionArtifact,\n",
    "                             data_validation_artifact = DataValidationArtifact)\n",
    "preprocessing_obj = trans.get_data_transformer_object()\n",
    "preprocessing_obj.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey,'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:448\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m columns:\n\u001b[1;32m--> 448\u001b[0m     col_idx \u001b[39m=\u001b[39m all_columns\u001b[39m.\u001b[39;49mget_loc(col)\n\u001b[0;32m    449\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(col_idx, numbers\u001b[39m.\u001b[39mIntegral):\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Date_of_Journey,'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m X \u001b[39m=\u001b[39m train_df\u001b[39m.\u001b[39mdrop(\u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m,axis \u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m preprocessing_obj\u001b[39m.\u001b[39;49mfit(X)\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:694\u001b[0m, in \u001b[0;36mColumnTransformer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit all transformers using X.\u001b[39;00m\n\u001b[0;32m    677\u001b[0m \n\u001b[0;32m    678\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39m    This estimator.\u001b[39;00m\n\u001b[0;32m    691\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m \u001b[39m# we use fit_transform to make sure to set sparse_output_ (for which we\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[39m# need the transformed data) to have consistent output type in predict\u001b[39;00m\n\u001b[1;32m--> 694\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_transform(X, y\u001b[39m=\u001b[39;49my)\n\u001b[0;32m    695\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:724\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    723\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 724\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_column_callables(X)\n\u001b[0;32m    725\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    727\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:426\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    424\u001b[0m         columns \u001b[39m=\u001b[39m columns(X)\n\u001b[0;32m    425\u001b[0m     all_columns\u001b[39m.\u001b[39mappend(columns)\n\u001b[1;32m--> 426\u001b[0m     transformer_to_input_indices[name] \u001b[39m=\u001b[39m _get_column_indices(X, columns)\n\u001b[0;32m    428\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_columns \u001b[39m=\u001b[39m all_columns\n\u001b[0;32m    429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transformer_to_input_indices \u001b[39m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32mf:\\Ineuron DS\\Internship\\FFP\\Flight_Fare_Predictions\\venv\\lib\\site-packages\\sklearn\\utils\\__init__.py:456\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    453\u001b[0m             column_indices\u001b[39m.\u001b[39mappend(col_idx)\n\u001b[0;32m    455\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 456\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mA given column is not a column of the dataframe\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    458\u001b[0m     \u001b[39mreturn\u001b[39;00m column_indices\n\u001b[0;32m    459\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "X = train_df.drop('Price',axis =1)\n",
    "preprocessing_obj.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('Price',axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
